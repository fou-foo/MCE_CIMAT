candidatos <- which(d==mini)
c.asig <- sample(candidatos, 1)#romper empates aleatoriamente
(1:K)[c.asig]#nueva asignacion de cluster para la observacion
}
)
#siguiendo el paper citado realizamos las iteraciones
#hacemos uso del shift
nuevo.cluster <- lapply(FUN=function(i){
#parte del calculo que no depende del shift
d <- rep(-1, k)
for(z in 1:k)
{
j <- which(data$cluster == z)
d[z]<- MK[i,i] - 2*sum(MK[i, j])/length(j) +
sum(MK[j,j])/(length(j))**2
d[is.na(d)] <- 0 #para cachar los errores de underflow
}
pis <- data.frame(table(data$cluster))
# suma del shift a las entradas correspondientes
for(z in 1:k)
{
if(z !=data[i,'cluster'])
{
d[z] <- d[z] + sigma +sigma/pis[z,'Freq']
}else{
d[z] <- d[z] + sigma -sigma/pis[data[i,'cluster'],'Freq']
}
}
d[is.na(d)] <- 0
mini <- min(d)
candidatos <- which(d==mini)
c.asig <- sample(candidatos, 1)#romper empates aleatoriamente
(1:K)[c.asig]#nueva asignacion de cluster para la observacion
}, X =1:dim(data)[1]#, mc.cores = detectCores()-2
)
for(x in 1:t)
{
#siguiendo el paper citado realizamos las iteraciones
#hacemos uso del shift
nuevo.cluster <- lapply(FUN=function(i){
#parte del calculo que no depende del shift
d <- rep(-1, k)
for(z in 1:k)
{
j <- which(data$cluster == z)
d[z]<- MK[i,i] - 2*sum(MK[i, j])/length(j) +
sum(MK[j,j])/(length(j))**2
d[is.na(d)] <- 0 #para cachar los errores de underflow
}
pis <- data.frame(table(data$cluster))
# suma del shift a las entradas correspondientes
for(z in 1:k)
{
if(z !=data[i,'cluster'])
{
d[z] <- d[z] + sigma +sigma/pis[z,'Freq']
}else{
d[z] <- d[z] + sigma -sigma/pis[data[i,'cluster'],'Freq']
}
}
d[is.na(d)] <- 0
mini <- min(d)
candidatos <- which(d==mini)
c.asig <- sample(candidatos, 1)#romper empates aleatoriamente
(1:k)[c.asig]#nueva asignacion de cluster para la observacion
}, X =1:dim(data)[1]#, mc.cores = detectCores()-2
)
data$cluster <- unlist(nuevo.cluster) #juntamos los resultados
}
library(Rcpp)
sourceCpp("C:\\Users\\fou-f\\Desktop\\MCE\\Second\\CienciaDeDatos\\tarea2\\kernel.cpp")
######### Implementacion de kernel k-means con shift basado en el paper:
#########Inderjit Dhillon, Yuqiang Guan and Brian Kulis.
#####A Unified view of Kernel k-means, Spectral Clustering and Graph Cuts.
Kernel.kmeans.init <- function(data )
{
# data (data.frame): data set con las observaciones y solo columnas numericas
#se calcula la matriz de distancias 'MK'
# ESTA FUNCION ES UN CLOSURE, REGRESA OTRA FUNCION, funciona como un constructor de clase del paradigma POO
# LA FINALIDAD ES CALCULUAR LA MATRIZ DE KERNEL UNA SOLA VEZ Y PROBAR DIFERENTES VALORES DE PARAMETROS
n <- dim(data)[1]
#comienza calculo de la matriz superior del kernel entre todos los pares de observaciones
MK <- matrix(rep(0, n*n), ncol = n)
data.matrix <- as.matrix(data)
p <- dim(data.matrix)[2]
MK <- CalculaKernel(MK, n, data.matrix, p)
#termina calculo de matriz de kernel
function(data, sigma,t, k )
{
#data (data.frame) con las observaciones a clasificar
#sigma (numeric): shift mencionado en el paper
#t (numeric): numero de iteraciones
#k (numeric): numero de clusters
data$cluster <- sample(1:k,dim(data)[1], replace = TRUE)#asignacion inicial aleatoria
for(x in 1:t)
{
#siguiendo el paper citado realizamos las iteraciones
#hacemos uso del shift
nuevo.cluster <- lapply(FUN=function(i){
#parte del calculo que no depende del shift
d <- rep(-1, k)
for(z in 1:k)
{
j <- which(data$cluster == z)
d[z]<- MK[i,i] - 2*sum(MK[i, j])/length(j) +
sum(MK[j,j])/(length(j))**2
d[is.na(d)] <- 0 #para cachar los errores de underflow
}
pis <- data.frame(table(data$cluster))
# suma del shift a las entradas correspondientes
for(z in 1:k)
{
if(z !=data[i,'cluster'])
{
d[z] <- d[z] + sigma +sigma/pis[z,'Freq']
}else{
d[z] <- d[z] + sigma -sigma/pis[data[i,'cluster'],'Freq']
}
}
d[is.na(d)] <- 0
mini <- min(d)
candidatos <- which(d==mini)
c.asig <- sample(candidatos, 1)#romper empates aleatoriamente
(1:k)[c.asig]#nueva asignacion de cluster para la observacion
}, X =1:dim(data)[1]#, mc.cores = detectCores()-2
)
data$cluster <- unlist(nuevo.cluster) #juntamos los resultados
}
return(data$cluster) #cluster finales
}
}
############################################################
set.seed(0)
#####simulacion de datos parecidos a los del paper mencionado
#####son dos circunferencias con centro (.5,.5) y radios 1 y 4
#####se agrega en cada eje ruido ~ N(0,sigma=1/10 ) y N(0,1/10)
r <- 1 #radio
n <- 100 #la cuarta parte del numero de puntos que se van a generar
#se genera la primer circunferencia con ruido
x <- seq(-r, r, length=n)
y1 <- sqrt(r**2-x**2) + rnorm(n,0,r/10)
y2 <- -sqrt(r**2-x**2) - rnorm(n,0,r/10)
m.a1 <- data.frame(x=rep(x+.5, 2), y = c(y1+.5,y2+.5), clase=1)
#se genera la segunda circunferencia con ruido
r <- 4
x <- seq(-r, r, length=n)
y1 <- sqrt(r**2-x**2) + rnorm(n,0,r/40)
y2 <- -sqrt(r**2-x**2) - rnorm(n,0,r/40)
m.a2 <- data.frame(x=rep(x+.5, 2), y = c(y1+.5,y2+.5), clase=2)
m.a <- rbind(m.a1, m.a2) #nuestro primer conjunto de prueba
m.a2 <- as.data.frame(scale(m.a[,1:2]) )
m.a[,1:2] <- m.a2
library(ggplot2)
ggplot(m.a,#visualizamos nuestro primer conjunto de prueba
aes(x=x, y=y, color = factor(clase))) + geom_point() +
theme_minimal() + theme(legend.position='none') +
ggtitle('Muestra aleatoria generada (400 obs)') +xlab('') + ylab('')
set.seed(0)
label<- kmeans(m.a, centers = 2, nstart = 100) #comparamos el desempeÃ±o de kmeans en vista
#                              #de que apriori sabemos que son 2 grupos
p1 <- ggplot(m.a,#visualizamos nuestro primer conjunto de prueba
aes(x=x, y=y, color = factor(label$cluster))) + geom_point() +
theme_minimal() + theme(legend.position='none') +
ggtitle('Agrupamiento de kmeans (accuracy 50%)') +xlab('') + ylab('')
#uso sobre
set.seed(0)
Kernel.kmeans.simu <- Kernel.kmeans.init(m.a[, 1:2])
labels <- Kernel.kmeans.simu(data= m.a[, 1:2], sigma = -1, t = 20, k =2)
m.a$cluster <- labels
p3 <- ggplot(m.a,#visualizamos nuestro primer conjunto de prueba
aes(x=x, y=y, color = factor(cluster))) + geom_point() +
theme_minimal() + theme(legend.position='none') +
ggtitle('Agrupamiento de kernel.kmeans (accuracy .72%)') +xlab('') + ylab('')
dim(m.a)[1]
table(m.a$clase,m.a$cluster)
99/400
p3
labels <- Kernel.kmeans.simu(data= m.a[, 1:2], sigma = -1, t = 100, k =2)
m.a$cluster <- labels
p3 <- ggplot(m.a,#visualizamos nuestro primer conjunto de prueba
aes(x=x, y=y, color = factor(cluster))) + geom_point() +
theme_minimal() + theme(legend.position='none') +
ggtitle('Agrupamiento de kernel.kmeans (accuracy .72%)') +xlab('') + ylab('')
p3
table(m.a$clase,m.a$cluster)
200+61
261/400
labels <- Kernel.kmeans.simu(data= m.a[, 1:2], sigma = -1, t = 1000, k =2)
colors()
?rgb
col2rgb(colors())
plot(1:10, pch=20, col =rainbow(n=10))
rainbow(n=10)
rainbow(n=16)
11-5
6*130
6*130*1.5
1170-550
130*6*1.5
130*6*1.5-550
2*130
170*4.5
170*9
10*1000/300
150*475/1000
*
61.75*20
1650*20
19*1.6
25*20
62*20
220*20
220*20*16
62*20*16
1968-2018
34/6
34/2
34/8
73.04*5/20
73.04*5
73.04*5*30
17*10*20
L <- c(.9,.7,.5)
L**2
L <- as.matrix(L)
L
L <- c(.9,.7,.5)
L <- as.matrix(L)
L%*%t(L)
phi <- matrix(c(.19,0,0,0,.51,0,0,0,.75))
phi
phi <- matrix(c(.19,0,0,0,.51,0,0,0,.75), ncol = 3)
phi
L%*%t(L) +phi
setwd('C:\\Users\\fou-f\\Desktop\\MCE\\Second\\AnalisisNumericoYOptimizacion\\Miniproyecto')
library(Rcpp) #libreria para codigo c++
library(RcppEigen) #libreria para codigo c++
library(RSpectra) #libreria para lanczos
library(imager) #libreria para leer imagenes
sourceCpp('W_float.cpp') #compilamos el programa en C++
t1 <- Sys.time() #medimos tiempo de ejecucion
dir()
imagen <- load.image('marco.jpg')
dim(imagen)
prod(dim(imagen)[1:2]/12.3) -160*120
plot(imagen) #visualizamos la imagen
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
#gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
gray.imagen <- imagen
gray.imagen <- resize(im = gray.imagen, size_x = 166, size_y = 110, size_z = 1, size_c = 1 )
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
dim(gray.imagen) #verificamos tamanio de la imagen
gray.imagen <- as.cimg(gray.imagen) #convertimos a imagen
plot(gray.imagen)
remove(imagen) #removemos del ambiente la imagen original para ahorra memoria
gc()
#estandarizacion escala de grises
M <- as.matrix(gray.imagen)
M <- (M -min(M))/(max(M)-min(M))
sig <- 1
siz <- 2*round(3*sig) + 1
#gray.imagen <- isoblur(gray.imagen, sigma =sig, gaussian=TRUE), decidimos no usar filtros pasa bajas
(h <- dim(M)[2])
(w <- dim(M)[1] )
edges <- ((h*w)*(h*w-1))*.1 #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
vecinos <- .0001
edges <- ((h*w)*(h*w-1))*vecinos #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
#r2 <- 25.*25. #se pueden quitar hasta el 90% de las aristas segun el paper pero hice mal la cuenta
r2 <- cuadrado**2
dim(M)
plot(as.cimg(M))
W <- Kernel_float( M, h, w, r2, sigJ, sigd)
vecinos <- .001
edges <- ((h*w)*(h*w-1))*vecinos #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
#r2 <- 25.*25. #se pueden quitar hasta el 90% de las aristas segun el paper pero hice mal la cuenta
r2 <- cuadrado**2
dim(M)
plot(as.cimg(M))
W <- Kernel_float( M, h, w, r2, sigJ, sigd)
setwd('C:\\Users\\fou-f\\Desktop\\MCE\\Second\\AnalisisNumericoYOptimizacion\\Miniproyecto')
library(Rcpp) #libreria para codigo c++
library(RcppEigen) #libreria para codigo c++
library(RSpectra) #libreria para lanczos
library(imager) #libreria para leer imagenes
sourceCpp('W_float.cpp') #compilamos el programa en C++
t1 <- Sys.time() #medimos tiempo de ejecucion
dir()
imagen <- load.image('marco.jpg')
dim(imagen)
prod(dim(imagen)[1:2]/12.3) -160*120
plot(imagen) #visualizamos la imagen
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
#gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
gray.imagen <- imagen
gray.imagen <- resize(im = gray.imagen, size_x = 166, size_y = 110, size_z = 1, size_c = 1 )
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
dim(gray.imagen) #verificamos tamanio de la imagen
gray.imagen <- as.cimg(gray.imagen) #convertimos a imagen
plot(gray.imagen)
remove(imagen) #removemos del ambiente la imagen original para ahorra memoria
gc()
#estandarizacion escala de grises
M <- as.matrix(gray.imagen)
M <- (M -min(M))/(max(M)-min(M))
sig <- 1
siz <- 2*round(3*sig) + 1
#gray.imagen <- isoblur(gray.imagen, sigma =sig, gaussian=TRUE), decidimos no usar filtros pasa bajas
(h <- dim(M)[2])
(w <- dim(M)[1] )
vecinos <- .001
edges <- ((h*w)*(h*w-1))*vecinos #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
#r2 <- 25.*25. #se pueden quitar hasta el 90% de las aristas segun el paper pero hice mal la cuenta
r2 <- cuadrado**2
dim(M)
plot(as.cimg(M))
W <- Kernel_float( M, h, w, r2, sigJ, sigd)
setwd('C:\\Users\\fou-f\\Desktop\\MCE\\Second\\AnalisisNumericoYOptimizacion\\Miniproyecto')
library(Rcpp) #libreria para codigo c++
library(RcppEigen) #libreria para codigo c++
library(RSpectra) #libreria para lanczos
library(imager) #libreria para leer imagenes
sourceCpp('W_float.cpp') #compilamos el programa en C++
t1 <- Sys.time() #medimos tiempo de ejecucion
dir()
imagen <- load.image('marco.jpg')
dim(imagen)
prod(dim(imagen)[1:2]/12.3) -160*120
plot(imagen) #visualizamos la imagen
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
#gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
gray.imagen <- imagen
#gray.imagen <- resize(im = gray.imagen, size_x = 166, size_y = 110, size_z = 1, size_c = 1 )
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
dim(gray.imagen) #verificamos tamanio de la imagen
gray.imagen <- as.cimg(gray.imagen) #convertimos a imagen
plot(gray.imagen)
remove(imagen) #removemos del ambiente la imagen original para ahorra memoria
gc()
#estandarizacion escala de grises
M <- as.matrix(gray.imagen)
M <- (M -min(M))/(max(M)-min(M))
setwd('C:\\Users\\fou-f\\Desktop\\MCE\\Second\\AnalisisNumericoYOptimizacion\\Miniproyecto')
library(Rcpp) #libreria para codigo c++
library(RcppEigen) #libreria para codigo c++
library(RSpectra) #libreria para lanczos
library(imager) #libreria para leer imagenes
sourceCpp('W_float.cpp') #compilamos el programa en C++
t1 <- Sys.time() #medimos tiempo de ejecucion
dir()
imagen <- load.image('marco.jpg')
dim(imagen)
prod(dim(imagen)[1:2]/12.3) -160*120
plot(imagen) #visualizamos la imagen
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
#gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
gray.imagen <- imagen
#gray.imagen <- resize(im = gray.imagen, size_x = 166, size_y = 110, size_z = 1, size_c = 1 )
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
dim(gray.imagen) #verificamos tamanio de la imagen
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
#gray.imagen <- resize(im = gray.imagen, size_x = 166, size_y = 110, size_z = 1, size_c = 1 )
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
dim(gray.imagen) #verificamos tamanio de la imagen
gray.imagen <- as.cimg(gray.imagen) #convertimos a imagen
plot(gray.imagen)
setwd('C:\\Users\\fou-f\\Desktop\\MCE\\Second\\AnalisisNumericoYOptimizacion\\Miniproyecto')
library(Rcpp) #libreria para codigo c++
library(RcppEigen) #libreria para codigo c++
library(RSpectra) #libreria para lanczos
library(imager) #libreria para leer imagenes
sourceCpp('W_float.cpp') #compilamos el programa en C++
t1 <- Sys.time() #medimos tiempo de ejecucion
dir()
imagen <- load.image('marco.jpg')
dim(imagen)
prod(dim(imagen)[1:2]/12.3) -160*120
plot(imagen) #visualizamos la imagen
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
#gray.imagen <- resize(im = gray.imagen, size_x = 166, size_y = 110, size_z = 1, size_c = 1 )
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
dim(gray.imagen) #verificamos tamanio de la imagen
gray.imagen <- as.cimg(gray.imagen) #convertimos a imagen
plot(gray.imagen)
remove(imagen) #removemos del ambiente la imagen original para ahorra memoria
gc()
#estandarizacion escala de grises
M <- as.matrix(gray.imagen)
M <- (M -min(M))/(max(M)-min(M))
sig <- 1
siz <- 2*round(3*sig) + 1
#gray.imagen <- isoblur(gray.imagen, sigma =sig, gaussian=TRUE), decidimos no usar filtros pasa bajas
(h <- dim(M)[2])
(w <- dim(M)[1] )
vecinos <- .001
edges <- ((h*w)*(h*w-1))*vecinos #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
#r2 <- 25.*25. #se pueden quitar hasta el 90% de las aristas segun el paper pero hice mal la cuenta
r2 <- cuadrado**2
dim(M)
plot(as.cimg(M))
W <- Kernel_float( M, h, w, r2, sigJ, sigd)
vecinos <- .001
edges <- ((h*w)*(h*w-1))*vecinos #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
#r2 <- 25.*25. #se pueden quitar hasta el 90% de las aristas segun el paper pero hice mal la cuenta
r2 <- cuadrado**2
dim(M)
plot(as.cimg(M))
W <- Kernel_float( M, h, w, r2, sigJ, sigd)
vecinos <- .0001
edges <- ((h*w)*(h*w-1))*vecinos #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
#r2 <- 25.*25. #se pueden quitar hasta el 90% de las aristas segun el paper pero hice mal la cuenta
r2 <- cuadrado**2
dim(M)
plot(as.cimg(M))
W <- Kernel_float( M, h, w, r2, sigJ, sigd)
gc()
setwd('C:\\Users\\fou-f\\Desktop\\MCE\\Second\\AnalisisNumericoYOptimizacion\\Miniproyecto')
library(Rcpp) #libreria para codigo c++
library(RcppEigen) #libreria para codigo c++
library(imager) #libreria para leer imagenes
library(RSpectra) #libreria para lanczos
sourceCpp('W_float.cpp') #compilamos el programa en C++
t1 <- Sys.time() #medimos tiempo de ejecucion
dir()
imagen <- load.image('marco.jpg')
dim(imagen)
prod(dim(imagen)[1:2]/12.3) -160*120
plot(imagen) #visualizamos la imagen
#############preprosesamiento  160*120 jala bien, recortamos la imaagen para que quepa en memoria
gray.imagen <- grayscale(imagen) #cambiamos a escala de grises
#gray.imagen <- resize(im = gray.imagen, size_x = 166, size_y = 110, size_z = 1, size_c = 1 )
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
#gray.imagen <- resize_halfXY(gray.imagen)
dim(gray.imagen) #verificamos tamanio de la imagen
gray.imagen <- as.cimg(gray.imagen) #convertimos a imagen
plot(gray.imagen)
remove(imagen) #removemos del ambiente la imagen original para ahorra memoria
gc()
#estandarizacion escala de grises
M <- as.matrix(gray.imagen)
M <- (M -min(M))/(max(M)-min(M))
sig <- 1
siz <- 2*round(3*sig) + 1
#gray.imagen <- isoblur(gray.imagen, sigma =sig, gaussian=TRUE), decidimos no usar filtros pasa bajas
(h <- dim(M)[2])
(w <- dim(M)[1] )
vecinos <- .0001
edges <- ((h*w)*(h*w-1))*vecinos #segun el paper se pueden remover hasta el 90% de las aristas deberia de ser ((h*w)*(h*w+1)/2)*.1
edges.sugerido <- edges/(h*w) #promedio de aristas por nodo
cuadrado <- edges.sugerido**.5 # vamos a fijar esta cantidad
cuadrado <- round(cuadrado) +1
sigJ <- 0.05 #ver paper
sigd <- 10#ver paper
#r2 <- 25.*25. #se pueden quitar hasta el 90% de las aristas segun el paper pero hice mal la cuenta
r2 <- cuadrado**2
dim(M)
plot(as.cimg(M))
W <- Kernel_float( M, h, w, r2, sigJ, sigd)
188-67
121/4
