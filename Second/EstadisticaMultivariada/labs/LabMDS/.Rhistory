#plot(x = su, data=stack, formula = factor(label) ~ .)
Y <- predict(su,stack)
table(Y, stack[,40])
table(Y, stack[,d+1])
ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
####################################
#####    J. Antonio Garcia #########
#####   jose.ramirez@cimat.mx ######
####################################
#########################################
# Construccion de la primer ilustracion #
#########################################
#generamos una muestra de dim 39 mormal multi
library(MASS)
n <- 20
d <- 39
set.seed(0)
I <- diag(rep(1, d))
pos <- as.data.frame(mvrnorm(n = n, mu = rep(2.2, d), Sigma = I))
neg <- as.data.frame(mvrnorm(n = n, mu = rep(-2.2, d), Sigma = I))
stack <- rbind(pos,neg)
pos.mean <- apply(pos, 2, mean)
neg.mean <- apply(neg, 2, mean)
w <- ginv(I) %*% (pos.mean - neg.mean)
w <- w/sum(w**2)**.5 #normalizamos el vector MDP
X <- ginv(cov(pos)) %*% (pos.mean - neg.mean)
X <- X/sum(X**2)**.5 #normalizamos el vector que define al frontera de Bayes
acos(sum(X*w))*360/(2*pi)
stack$label <- 1
stack$label[(n+1):(2*n)] <- -1
Y <- X
Y[-c(1,2)] <- 0
Y[1] <- X[2]
Y[2] <- -X[1] #elegimos un vector perpenticular a X
sum(Y*X)
M <- cbind(X, Y , w)
pos.proyec <- as.matrix(pos)%*%M
neg.proyec <- as.matrix(neg)%*%M
pos.proyec <- as.data.frame(pos.proyec)
neg.proyec <- as.data.frame(neg.proyec)
pos.proyec$label <- '+1'
neg.proyec$label <- '-1'
proyec <- rbind(pos.proyec, neg.proyec)
library(ggplot2)
ggplot(data = proyec, aes(x=V1, y=V2, color=label))+geom_point() +
stat_function(fun = function(z){z*(w[1]/w[2])}, aes(colour = I('pink')))+
geom_hline(yintercept=0, aes(colour=I('red')),     show.legend = NA)
ggplot(data = proyec, aes(x=V1, fill=label, colour=label))+geom_density()+
geom_rug(sides="b")
ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
####################################
#####    J. Antonio Garcia #########
#####   jose.ramirez@cimat.mx ######
####################################
#########################################
# Construccion de la primer ilustracion #
#########################################
#generamos una muestra de dim 39 mormal multi
library(MASS)
n <- 20
d <- 200
set.seed(0)
I <- diag(rep(1, d))
pos <- as.data.frame(mvrnorm(n = n, mu = rep(2.2, d), Sigma = I))
neg <- as.data.frame(mvrnorm(n = n, mu = rep(-2.2, d), Sigma = I))
stack <- rbind(pos,neg)
pos.mean <- apply(pos, 2, mean)
neg.mean <- apply(neg, 2, mean)
w <- ginv(I) %*% (pos.mean - neg.mean)
w <- w/sum(w**2)**.5 #normalizamos el vector MDP
X <- ginv(cov(pos)) %*% (pos.mean - neg.mean)
X <- X/sum(X**2)**.5 #normalizamos el vector que define al frontera de Bayes
acos(sum(X*w))*360/(2*pi)
stack$label <- 1
stack$label[(n+1):(2*n)] <- -1
Y <- X
Y[-c(1,2)] <- 0
Y[1] <- X[2]
Y[2] <- -X[1] #elegimos un vector perpenticular a X
sum(Y*X)
M <- cbind(X, Y , w)
pos.proyec <- as.matrix(pos)%*%M
neg.proyec <- as.matrix(neg)%*%M
pos.proyec <- as.data.frame(pos.proyec)
neg.proyec <- as.data.frame(neg.proyec)
pos.proyec$label <- '+1'
neg.proyec$label <- '-1'
proyec <- rbind(pos.proyec, neg.proyec)
library(ggplot2)
ggplot(data = proyec, aes(x=V1, y=V2, color=label))+geom_point() +
stat_function(fun = function(z){z*(w[1]/w[2])}, aes(colour = I('pink')))+
geom_hline(yintercept=0, aes(colour=I('red')),     show.legend = NA)
ggplot(data = proyec, aes(x=V1, fill=label, colour=label))+geom_density()+
geom_rug(sides="b")
ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
####################################
#####    J. Antonio Garcia #########
#####   jose.ramirez@cimat.mx ######
####################################
#########################################
# Construccion de la primer ilustracion #
#########################################
#generamos una muestra de dim 39 mormal multi
library(MASS)
n <- 20
d <- 2000
set.seed(0)
I <- diag(rep(1, d))
pos <- as.data.frame(mvrnorm(n = n, mu = rep(2.2, d), Sigma = I))
neg <- as.data.frame(mvrnorm(n = n, mu = rep(-2.2, d), Sigma = I))
stack <- rbind(pos,neg)
pos.mean <- apply(pos, 2, mean)
neg.mean <- apply(neg, 2, mean)
w <- ginv(I) %*% (pos.mean - neg.mean)
w <- w/sum(w**2)**.5 #normalizamos el vector MDP
X <- ginv(cov(pos)) %*% (pos.mean - neg.mean)
X <- X/sum(X**2)**.5 #normalizamos el vector que define al frontera de Bayes
acos(sum(X*w))*360/(2*pi)
stack$label <- 1
stack$label[(n+1):(2*n)] <- -1
Y <- X
Y[-c(1,2)] <- 0
Y[1] <- X[2]
Y[2] <- -X[1] #elegimos un vector perpenticular a X
sum(Y*X)
M <- cbind(X, Y , w)
pos.proyec <- as.matrix(pos)%*%M
neg.proyec <- as.matrix(neg)%*%M
pos.proyec <- as.data.frame(pos.proyec)
neg.proyec <- as.data.frame(neg.proyec)
pos.proyec$label <- '+1'
neg.proyec$label <- '-1'
proyec <- rbind(pos.proyec, neg.proyec)
library(ggplot2)
ggplot(data = proyec, aes(x=V1, y=V2, color=label))+geom_point() +
stat_function(fun = function(z){z*(w[1]/w[2])}, aes(colour = I('pink')))+
geom_hline(yintercept=0, aes(colour=I('red')),     show.legend = NA)
ggplot(data = proyec, aes(x=V1, fill=label, colour=label))+geom_density()+
geom_rug(sides="b")
ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
####################################
#####    J. Antonio Garcia #########
#####   jose.ramirez@cimat.mx ######
####################################
#########################################
# Construccion de la primer ilustracion #
#########################################
#generamos una muestra de dim 39 mormal multi
library(MASS)
n <- 20
d <- 1000
set.seed(100000)
I <- diag(rep(1, d))
pos <- as.data.frame(mvrnorm(n = n, mu = rep(2.2, d), Sigma = I))
neg <- as.data.frame(mvrnorm(n = n, mu = rep(-2.2, d), Sigma = I))
stack <- rbind(pos,neg)
pos.mean <- apply(pos, 2, mean)
neg.mean <- apply(neg, 2, mean)
w <- ginv(I) %*% (pos.mean - neg.mean)
w <- w/sum(w**2)**.5 #normalizamos el vector MDP
X <- ginv(cov(pos)) %*% (pos.mean - neg.mean)
X <- X/sum(X**2)**.5 #normalizamos el vector que define al frontera de Bayes
acos(sum(X*w))*360/(2*pi)
stack$label <- 1
stack$label[(n+1):(2*n)] <- -1
Y <- X
Y[-c(1,2)] <- 0
Y[1] <- X[2]
Y[2] <- -X[1] #elegimos un vector perpenticular a X
sum(Y*X)
M <- cbind(X, Y , w)
pos.proyec <- as.matrix(pos)%*%M
neg.proyec <- as.matrix(neg)%*%M
pos.proyec <- as.data.frame(pos.proyec)
neg.proyec <- as.data.frame(neg.proyec)
pos.proyec$label <- '+1'
neg.proyec$label <- '-1'
proyec <- rbind(pos.proyec, neg.proyec)
library(ggplot2)
ggplot(data = proyec, aes(x=V1, y=V2, color=label))+geom_point() +
stat_function(fun = function(z){z*(w[1]/w[2])}, aes(colour = I('pink')))+
geom_hline(yintercept=0, aes(colour=I('red')),     show.legend = NA)
ggplot(data = proyec, aes(x=V1, fill=label, colour=label))+geom_density()+
geom_rug(sides="b")
ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
10**2
100**2
i <- (1:100)**2
i
?mvrnorm
#########################################
# Construccion de la primer ilustracion #
#########################################
#generamos una muestra de dim 39 mormal multi
library(MASS)
i <- (1:100)**2
for (j in i){
n <- 20
d <- i
set.seed(100000)
I <- diag(rep(1, d))
pos <- as.data.frame(mvrnorm(n = n, mu = rep(2.2, d), Sigma = I))
neg <- as.data.frame(mvrnorm(n = n, mu = rep(-2.2, d), Sigma = I))
stack <- rbind(pos,neg)
pos.mean <- apply(pos, 2, mean)
neg.mean <- apply(neg, 2, mean)
w <- ginv(I) %*% (pos.mean - neg.mean)
w <- w/sum(w**2)**.5 #normalizamos el vector MDP
X <- ginv(cov(pos)) %*% (pos.mean - neg.mean)
X <- X/sum(X**2)**.5 #normalizamos el vector que define al frontera de Bayes
acos(sum(X*w))*360/(2*pi)
stack$label <- 1
stack$label[(n+1):(2*n)] <- -1
Y <- X
Y[-c(1,2)] <- 0
Y[1] <- X[2]
Y[2] <- -X[1] #elegimos un vector perpenticular a X
sum(Y*X)
M <- cbind(X, Y , w)
pos.proyec <- as.matrix(pos)%*%M
neg.proyec <- as.matrix(neg)%*%M
pos.proyec <- as.data.frame(pos.proyec)
neg.proyec <- as.data.frame(neg.proyec)
pos.proyec$label <- '+1'
neg.proyec$label <- '-1'
proyec <- rbind(pos.proyec, neg.proyec)
library(ggplot2)
p1 <- ggplot(data = proyec, aes(x=V1, y=V2, color=label))+geom_point() +
stat_function(fun = function(z){z*(w[1]/w[2])}, aes(colour = I('pink')))+
geom_hline(yintercept=0, aes(colour=I('red')),     show.legend = NA)
plot(p1)
p2 <- ggplot(data = proyec, aes(x=V1, fill=label, colour=label))+geom_density()+
geom_rug(sides="b")
plot(p2)
p3 <- ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
plot(p3)
scan()
}
n <- 20
d <- i
set.seed(100000)
I <- diag(rep(1, d))
rep(1, d)
#########################################
# Construccion de la primer ilustracion #
#########################################
#generamos una muestra de dim 39 mormal multi
library(MASS)
i <- (1:100)**2
for (j in i){
n <- 20
d <- j
set.seed(100000)
I <- diag(rep(1, d))
pos <- as.data.frame(mvrnorm(n = n, mu = rep(2.2, d), Sigma = I))
neg <- as.data.frame(mvrnorm(n = n, mu = rep(-2.2, d), Sigma = I))
stack <- rbind(pos,neg)
pos.mean <- apply(pos, 2, mean)
neg.mean <- apply(neg, 2, mean)
w <- ginv(I) %*% (pos.mean - neg.mean)
w <- w/sum(w**2)**.5 #normalizamos el vector MDP
X <- ginv(cov(pos)) %*% (pos.mean - neg.mean)
X <- X/sum(X**2)**.5 #normalizamos el vector que define al frontera de Bayes
acos(sum(X*w))*360/(2*pi)
stack$label <- 1
stack$label[(n+1):(2*n)] <- -1
Y <- X
Y[-c(1,2)] <- 0
Y[1] <- X[2]
Y[2] <- -X[1] #elegimos un vector perpenticular a X
sum(Y*X)
M <- cbind(X, Y , w)
pos.proyec <- as.matrix(pos)%*%M
neg.proyec <- as.matrix(neg)%*%M
pos.proyec <- as.data.frame(pos.proyec)
neg.proyec <- as.data.frame(neg.proyec)
pos.proyec$label <- '+1'
neg.proyec$label <- '-1'
proyec <- rbind(pos.proyec, neg.proyec)
library(ggplot2)
p1 <- ggplot(data = proyec, aes(x=V1, y=V2, color=label))+geom_point() +
stat_function(fun = function(z){z*(w[1]/w[2])}, aes(colour = I('pink')))+
geom_hline(yintercept=0, aes(colour=I('red')),     show.legend = NA)
plot(p1)
p2 <- ggplot(data = proyec, aes(x=V1, fill=label, colour=label))+geom_density()+
geom_rug(sides="b")
plot(p2)
p3 <- ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
plot(p3)
scan()
}
#########################################
# Construccion de la primer ilustracion #
#########################################
#generamos una muestra de dim 39 mormal multi
library(MASS)
i <- (2:100)**2
for (j in i){
n <- 20
d <- j
set.seed(100000)
I <- diag(rep(1, d))
pos <- as.data.frame(mvrnorm(n = n, mu = rep(2.2, d), Sigma = I))
neg <- as.data.frame(mvrnorm(n = n, mu = rep(-2.2, d), Sigma = I))
stack <- rbind(pos,neg)
pos.mean <- apply(pos, 2, mean)
neg.mean <- apply(neg, 2, mean)
w <- ginv(I) %*% (pos.mean - neg.mean)
w <- w/sum(w**2)**.5 #normalizamos el vector MDP
X <- ginv(cov(pos)) %*% (pos.mean - neg.mean)
X <- X/sum(X**2)**.5 #normalizamos el vector que define al frontera de Bayes
acos(sum(X*w))*360/(2*pi)
stack$label <- 1
stack$label[(n+1):(2*n)] <- -1
Y <- X
Y[-c(1,2)] <- 0
Y[1] <- X[2]
Y[2] <- -X[1] #elegimos un vector perpenticular a X
sum(Y*X)
M <- cbind(X, Y , w)
pos.proyec <- as.matrix(pos)%*%M
neg.proyec <- as.matrix(neg)%*%M
pos.proyec <- as.data.frame(pos.proyec)
neg.proyec <- as.data.frame(neg.proyec)
pos.proyec$label <- '+1'
neg.proyec$label <- '-1'
proyec <- rbind(pos.proyec, neg.proyec)
library(ggplot2)
p1 <- ggplot(data = proyec, aes(x=V1, y=V2, color=label))+geom_point() +
stat_function(fun = function(z){z*(w[1]/w[2])}, aes(colour = I('pink')))+
geom_hline(yintercept=0, aes(colour=I('red')),     show.legend = NA)
plot(p1)
p2 <- ggplot(data = proyec, aes(x=V1, fill=label, colour=label))+geom_density()+
geom_rug(sides="b")
plot(p2)
p3 <- ggplot(data = proyec, aes(x=label, y=V1, fill=label, colour=label))+geom_boxplot()
plot(p3)
r <- scan()
}
gc()
shiny::runApp('C:/Users/fou-f/Desktop/MCE_CIMAT/Second/CienciaDeDatos/DWD')
####################################
#####    J. Antonio Garcia #########
#####   jose.ramirez@cimat.mx ######
####################################
setwd('C:\\Users\\fou-f\\Desktop\\MCE\\Second\\CienciaDeDatos\\DWD')
runApp('C:/Users/fou-f/Desktop/MCE_CIMAT/Second/CienciaDeDatos/DWD')
####################################
#####    J. Antonio Garcia #########
#####   jose.ramirez@cimat.mx ######
####################################
library(shinydashboard)
citation('shinydashboard')
runApp('C:/Users/fou-f/Desktop/MCE_CIMAT/Second/CienciaDeDatos/DWD')
runApp('C:/Users/fou-f/Desktop/MCE_CIMAT/Second/CienciaDeDatos/DWD')
setwd('C:\\Users\\fou-f\\Desktop\\MCE_CIMAT\\Second\\EstadisticaMultivariada\\labs\\LabMDS')
18*12
18*12
# Practica 5. Aplicacion de modelos de escalamiento multidimensional
library("MASS")
library("alr3")
library("stats")
library("scatterplot3d")
library("smacof")
install.packages("smacof")
library("smacof")
prox_nations <- read.csv("DATOS_NACIONES.csv", header = TRUE, sep = ",", quote = "\"",dec = ".", fill = TRUE, na.strings = "NA")
#nombre de las naciones
nombres<- names(prox_nations)
nombres
#Nota: como los datos representan similaridades, debemos transformarlas a disimilaridades.
#primero identificamos el valor maximo en las similaridades, entonces las similaridades las transformamos a disimilaridades como disi=(max(sim)+1)-sim
maximo <- max(prox_nations)+1
disim_nations <- maximo-prox_nations
#sin embargo los elementos de la diagonal de la matriz de disimilaridades(disim_nations) son distintos de cero, todos
#son iguales al maximo de la similaridades. Entonces los elementos diagonales de la matriz de disimilaridades los
#convertimos en ceros
disim_nations <- disim_nations- diag(maximo,length(disim_nations),length(disim_nations))
#sin embargo los elementos de la diagonal de la matriz de disimilaridades(disim_nations) son distintos de cero, todos
#son iguales al maximo de la similaridades. Entonces los elementos diagonales de la matriz de disimilaridades los
#convertimos en ceros
disim_nations <- disim_nations- diag(maximo,length(disim_nations),length(disim_nations))
disim_nations
?cmdscale
# se extrae la configuracion solucion X
config_nations<-resul_mds_clas$points
#funci?n que realiza el mds clasico
resul_mds_clas<-cmdscale(disim_nations, k = 2, eig = TRUE, add = FALSE, x.ret = FALSE)
prox_nations <- read.csv("DATOS_NACIONES.csv", header = TRUE, sep = ",", quote = "\"",dec = ".", fill = TRUE, na.strings = "NA")
#nombre de las naciones
nombres<- names(prox_nations)
#Nota: como los datos representan similaridades, debemos transformarlas a disimilaridades.
#primero identificamos el valor maximo en las similaridades, entonces las similaridades las transformamos a disimilaridades como disi=(max(sim)+1)-sim
maximo <- max(prox_nations)+1
disim_nations <- maximo-prox_nations
#sin embargo los elementos de la diagonal de la matriz de disimilaridades(disim_nations) son distintos de cero, todos
#son iguales al maximo de la similaridades. Entonces los elementos diagonales de la matriz de disimilaridades los
#convertimos en ceros
disim_nations <- disim_nations- diag(maximo,length(disim_nations),length(disim_nations))
#funci?n que realiza el mds clasico
resul_mds_clas<-cmdscale(disim_nations, k = 2, eig = TRUE, add = FALSE, x.ret = FALSE)
# se extrae la configuracion solucion X
config_nations<-resul_mds_clas$points
#se a?aden los nombres de las naciones a la configuracion solucion X
dimnames(config_nations)[[1]]<-nombres
setwd('C:\\Users\\fou-f\\Desktop\\MCE_CIMAT\\Second\\EstadisticaMultivariada\\labs\\LabMDS')
# Practica 5. Aplicacion de modelos de escalamiento multidimensional
library("MASS")
library("alr3")
library("stats")
library("scatterplot3d")
library("smacof")
prox_nations <- read.csv("DATOS_NACIONES.csv", header = TRUE, sep = ",", quote = "\"",dec = ".", fill = TRUE, na.strings = "NA")
#nombre de las naciones
nombres<- names(prox_nations)
#Nota: como los datos representan similaridades, debemos transformarlas a disimilaridades.
#primero identificamos el valor maximo en las similaridades, entonces las similaridades las transformamos a disimilaridades como disi=(max(sim)+1)-sim
maximo <- max(prox_nations)+1
disim_nations <- maximo-prox_nations
#sin embargo los elementos de la diagonal de la matriz de disimilaridades(disim_nations) son distintos de cero, todos
#son iguales al maximo de la similaridades. Entonces los elementos diagonales de la matriz de disimilaridades los
#convertimos en ceros
disim_nations <- disim_nations- diag(maximo,length(disim_nations),length(disim_nations))
#funci?n que realiza el mds clasico
resul_mds_clas<-cmdscale(disim_nations, k = 2, eig = TRUE, add = FALSE, x.ret = FALSE)
# se extrae la configuracion solucion X
config_nations<-resul_mds_clas$points
#se a?aden los nombres de las naciones a la configuracion solucion X
dimnames(config_nations)[[1]]<-nombres
plot(config_nations[,1],config_nations[,2],main="configuracion solucion mediante mds clasico",ylim=range(config_nations[,1]),
xlab="dim 1",ylab="dim 2",type="n",lwd=2)
text(config_nations[,1],config_nations[,2],
labels=abbreviate(row.names(config_nations),minlength=8),cex=0.6,lwd=2)
# se obtiene la proporcion de la varianza total explicada por las dos dimensiones
resul_mds_clas$GOF
resul_mds_clas
########################################################################
# Se aplica el modelo de minimos cuadrados utilizando el algoritmo SMACOF
resul_mds_mc <- smacofSym(disim_nations, ndim=2,weightmat = NULL, init = "torgerson",
verbose = TRUE, relax = FALSE, itmax = 1000, eps = 1e-06)
#se grafica la configuracion solucion obtenida mediante smacof,  incluyendo los nombres de los paises
config_nations_mc<-resul_mds_mc$conf
plot(config_nations_mc[,1],config_nations_mc[,2],main="configuracion solucion mediante smacof",ylim=range(config_nations_mc[,1]),
xlab="Dim 1",ylab="Dim 2",type="n",lwd=2)
text(config_nations_mc[,1],config_nations_mc[,2],
labels=abbreviate(nombres,minlength=8),cex=0.6,lwd=2)
?smacofSym
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,main = "Grafica de las disparidades vs las distancias ajustadas", plot.type = "resplot")
resul_mds_mc$dhat
resul_mds_mc$delta - resul_mds_mc$dhat
corr(resul_mds_mc$delta, resul_mds_mc$dhat)
cor(resul_mds_mc$delta, resul_mds_mc$dhat)
(resul_mds_mc$delta- resul_mds_mc$dhat)
unlist(resul_mds_mc$delta)
cor(unlist(resul_mds_mc$delta), unlist(resul_mds_mc$dhat))
str(resul_mds_mc)
resul_mds_mc$delta
unlist(resul_mds_mc$delta)
as.vector(resul_mds_mc$delta)
cor(as.vector(resul_mds_mc$delta), as.vector(resul_mds_mc$dhat))
(as.vector(resul_mds_mc$delta)- as.vector(resul_mds_mc$dhat))
plot(as.vector(resul_mds_mc$delta), as.vector(resul_mds_mc$dhat))
plot(as.vector(resul_mds_mc$delta)**2, as.vector(resul_mds_mc$dhat)**2)
resul_mds_mc
plot(config_nations_mc[,1],config_nations_mc[,2],main="configuracion solucion mediante smacof",ylim=range(config_nations_mc[,1]),
xlab="Dim 1",ylab="Dim 2",type="n",lwd=2)
text(config_nations_mc[,1],config_nations_mc[,2],
labels=abbreviate(nombres,minlength=8),cex=0.6,lwd=2)
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,main = "Grafica de las disparidades vs las distancias ajustadas", plot.type = "resplot")
class(resul_mds_mc)
?plot.smacof
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,main = "Grafica de las disparidades vs las distancias ajustadas", plot.type = "resplot",
plot.type='"bubbleplot"')
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,main = "Grafica de las disparidades vs las distancias ajustadas",
plot.type='"bubbleplot"')
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,main = "Grafica de las disparidades vs las distancias ajustadas",
plot.type='"bubbleplot"')
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,
main = "Grafica de las disparidades vs las distancias ajustadas",
plot.type="bubbleplot")
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,
main = "Grafica de las disparidades vs las distancias ajustadas",
plot.type="confplot")
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,
main = "Grafica de las disparidades vs las distancias ajustadas",
plot.type="Shepard")
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,
main = "Grafica de las disparidades vs las distancias ajustadas",
plot.type="stressplot")
#se obtiene el diagrama de shepard, para evaluar la calidad de la soluci?n, graficando
#las disparidades vs las distancias ajustadas
plot(resul_mds_mc,
main = "Grafica de las disparidades vs las distancias ajustadas",
plot.type="histogram")
